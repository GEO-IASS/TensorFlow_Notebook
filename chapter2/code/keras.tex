\section{Keras}
\subsection{损失的目标函数}
\begin{itemize}
\item mean\_squared\_error或者mse
\item mean\_absolute\_error或者mae
\item mean_absolute\_percentage\_error或者mape
\item mean\_squared\_logarithmic\_error或者msle
\item squared\_hinge
\itme hinge
\item binary\_crossentropy(对数损失logloss)
\item logcosh
\item categorical\_crossentropy:多类对数损失，使用该目标函数是需要将标签转化为形如(nb\_samples,nb\_classes)的二值序列。
\item sparse\_categorical\_crossentropy:如上，单接收稀疏标签。注意使用该函数时仍然需要你的标签和输出值的维度相同，你可能需要在标签数据上增加一个维度:np.expand\_dims(y,-1)
\item kullback\_leibler\_divergence:从预测值概率分布Q到真实值概率分布P的信息增益，用以独享两个分布的差异。
\item poisson:(prefictions-targets*log(predictions))的均值。
\item cosine\_proximity:即预测值和真实标签的余弦距离平均值的相反数。
\end{itemize}
\begin{quote}
当使用categorical\_crossentropy作为目标函数时，标签应该为多类模式，即one-hot编码的向量，而不是单个数值，可以使用工具中的to\_categorical函数完成该转换。
\end{quote}
\begin{python}
from keras.utils.np_utils import to_categorical

categorical_labels = to_categorical(int_labels, num_classes=None)
\end{python}